{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "079b3308",
   "metadata": {},
   "source": [
    "# Assignment 3: Explainable AI tools\n",
    "\n",
    "The goal of this assignment is to learn how to generate explanations for machine learning model predictions. We will work with the German Credit dataset that we used in the previous assignment, and consider two popular explanation mechanisms-- LIME and SHAP-- for a couple of machine learning models.\n",
    "\n",
    "This notebook has four stages in which we will: \n",
    "1. Generate explanations for a learned logistic regression classifier using LIME.\n",
    "2. Generate explanations for the same classifier using SHAP.\n",
    "3. Compare the explanations generated by LIME and SHAP.\n",
    "4. Explore LIME and SHAP for another classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81862844",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap==0.39.0\n",
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ee0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import sklearn.preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "from IPython.display import Markdown, display, Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from lime import submodular_pick\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "from IPython.core.display import HTML \n",
    "import operator\n",
    "from collections import defaultdict\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f1efd",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "As in the previous assignments, we will work with the German Credit dataset, which is one of the most popular datasets in the XAI literature. (More information about the dataset can be found here: https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data).\n",
    "\n",
    "The task for this dataset is to predict whether an individual is a good credit risk or a bad credit risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd54fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['status', 'duration', 'credit_hist', 'purpose', 'credit_amt', 'savings', 'employment',\\\n",
    "            'install_rate', 'personal_status', 'debtors', 'residence', 'property', 'age', 'install_plans',\\\n",
    "            'housing', 'num_credits', 'job', 'num_liable', 'telephone', 'foreign_worker', 'credit']\n",
    "data_df = pd.read_table('german.data', names=cols, sep=\" \", index_col=False)\n",
    "data_df['credit'] = data_df['credit'].replace(2, 0) #1 = Good, 2= Bad credit risk\n",
    "y = data_df['credit']\n",
    "\n",
    "print(\"Shape: \", data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4da2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of feature names (excluding the outcome variable)\n",
    "feature_names = data_df.columns[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5582ae9",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "In this assignment, we will utilize sklearn's built-in encoders for data preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b850e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "labels = data_df.iloc[:,-1]\n",
    "le= sklearn.preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)\n",
    "class_names = le.classes_\n",
    "data = data_df.iloc[:,:-1]\n",
    "le_label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Class names: \", class_names)\n",
    "print(\"Label mapping: \", le_label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df1046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are categorical varibles that we need to make dummies for\n",
    "print(data.dtypes)\n",
    "\n",
    "# Get a list of which variables are categorical\n",
    "categorical_features  = [i for i in range(len(data.dtypes)) if data.dtypes[i]=='object']\n",
    "print(\"Indices of categorical features: \", categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d16bcbb",
   "metadata": {},
   "source": [
    "Our explainers will require us to provide categorical features as a single column, not as dummies, so we cannot just explode these columns using one-hot encoding the way we normally would during pre-processing.\n",
    "\n",
    "Instead, we will use some sklearn tools to take the following steps:\n",
    "<ul>\n",
    "<li>Encode the existing feature values with a number corresponding to each feature value.\n",
    "<li>Make a dictionary storing the relationship between the original string feature value and the number we have replaced it with (categorical_names).\n",
    "<li>Make a function that we can use later to transform categorical features into dummies.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3558f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_names = {}\n",
    "for feature in categorical_features:\n",
    "    print(\"Feature: \", feature)\n",
    "    # Use label encoder to map categories to numbers\n",
    "    le = sklearn.preprocessing.LabelEncoder()\n",
    "    le.fit(data.iloc[:, feature])\n",
    "    # Replace the feature values with corresponding numbers in the original data\n",
    "    data.iloc[:, feature] = le.transform(data.iloc[:, feature])\n",
    "    # Store and print the mappings for reference later\n",
    "    categorical_names[feature] = le.classes_\n",
    "    print(categorical_names[feature])\n",
    "    print(\"==================================================\")\n",
    "    \n",
    "# This variable stores the original names of each feature value for each feature\n",
    "categorical_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465148cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the encoder function to transform the categorical columns into dummies-- \n",
    "# but we cannot do that to the original dataset if we want to use LIME\n",
    "encoder = ColumnTransformer(transformers=[('get_dummies', OneHotEncoder(), categorical_features)], remainder='passthrough')\n",
    "encoder = encoder.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b111057e",
   "metadata": {},
   "source": [
    "### Split the data into training and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfafb812",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, labels_train, labels_test = sklearn.model_selection.train_test_split(data, labels, train_size=0.80, random_state=10)\n",
    "print(\"Train shape: \", train.shape)\n",
    "print(\"Test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d662cbe1",
   "metadata": {},
   "source": [
    "### Fit the model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0333c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.LogisticRegression(penalty=\"l2\", C=0.1)\n",
    "model.fit(train, labels_train)\n",
    "\n",
    "# model predictions\n",
    "pred_labels_test = model.predict((test))\n",
    "print(\"Test set accuracy: \", sklearn.metrics.accuracy_score(labels_test, pred_labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The prediction function `predict_fn` below, takes an instance and outputs prediction probabilities predicted by the learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn = lambda x: model.predict_proba(x).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: LIME Explanations\n",
    "We went over LIME (Local Interpretable Model-agnostic Explanations) in class. In this section, we will utilize the lime package to generate local and global explanations for a learned model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d75f5fc",
   "metadata": {},
   "source": [
    "### Generate the LIME explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIME can be used for structured (tabular), unstructured (text) and image data. In this assignment, we will explore LIME's tabular explainers, which require a training set (as seen in the first parameter in the code below). The training data is used to create perturbed instances with which the learned model is probed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221cf1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(train.values, \n",
    "                                                   feature_names=feature_names,\n",
    "                                                   class_names=class_names,\n",
    "                                                   categorical_features=categorical_features, \n",
    "                                                   categorical_names=categorical_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c443940f",
   "metadata": {},
   "source": [
    "### LIME's local explanations\n",
    "\n",
    "We will now explain a single test instance by using LIME's explainer created above. Select the test instance to explain by setting `idx_to_explain` below. You can also select the maximum number of features that you want to see in the  explanation by setting the `num_features` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ad8e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_explain = # index of the instance\n",
    "print('Actual class: ', labels_test[idx_to_explain])\n",
    "\n",
    "# Get explanation\n",
    "exp = explainer.explain_instance((test.values[idx_to_explain]), predict_fn, num_features=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b34a2c",
   "metadata": {},
   "source": [
    "### Visualize the explanation \n",
    "Now that the explanation is ready, let's visualize it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b784017",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(show_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20b4d24",
   "metadata": {},
   "source": [
    "#### Q1. Explain the LIME output above. In this example, which features have the biggest impact?\n",
    "\n",
    "**Your analysis here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0996590",
   "metadata": {},
   "source": [
    "You can also see the explanations as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab54354",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aca323f",
   "metadata": {},
   "source": [
    "#### Q2. Select another test instance and explain its LIME prediction.Identify the features that have a positive and those that have a negative contribution toward the outcome.\n",
    "\n",
    "**Your analysis here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8ee875",
   "metadata": {},
   "source": [
    "### LIME' global explanations\n",
    "\n",
    "As we just saw, explanations can vary a lot depending on what instance we pick. While this is great for explaining a single prediction, it makes it hard to give someone an intuition for \"how the model makes decisions\" in general. \n",
    "\n",
    "That is where the **Submodular picker** comes in. It picks useful, representative examples that together give a **global explanation** for the model's behavior. (We briefly discussed submodular picker in class).\n",
    "\n",
    "The algorithm generates global explanations using submodular picker in the following steps:\n",
    "<ul>\n",
    "    <li>Compute explanations for each of the examples in the dataset.</li>\n",
    "    <li>The <i>coverage</i> step that we discussed in class determine which features are important in explaining a lot of the predictions i.e., features that seem <i>globally</i> important. The idea is to identify instances that cover a lot of the globally important features. </li>\n",
    "    <li>The above is done by greedily selecting an example where the top globally important feature is part of the local explanation for that one example's prediction.</li>\n",
    "    <li>Continue selecting examples until we have covered as many of the globally important features as possible, constrained by the number of features that the user wants returned (num_exps_desired).</li>\n",
    "    </ul>\n",
    "\n",
    "You can read the details of how this is done in the paper. More details on the function can be found here (https://lime-ml.readthedocs.io/en/latest/lime.html#lime-submodular-pick-module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea9920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_obj = submodular_pick.SubmodularPick(explainer, train.values, predict_fn, sample_size=10, \n",
    "                                        num_features=5, num_exps_desired=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sp_obj object contains the `num_exps_desired` explanation objects chosen by the submodular pick algorithm. Let's take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_obj.V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each of the chosen instance, let's see if the model predicted the correct label and the explanations generated for each of the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9340beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in sp_obj.V:\n",
    "    exp = explainer.explain_instance(test.values[ind], predict_fn, num_features=5)\n",
    "    print(\"Actual class: \", labels_test[ind])\n",
    "    exp.show_in_notebook(show_all=False)\n",
    "    print(\"==========================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad60cd6",
   "metadata": {},
   "source": [
    "#### Q3. Based on these chosen examples, what can you say about how the trained model makes decisions?\n",
    "\n",
    "**Your analysis here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d238e850",
   "metadata": {},
   "source": [
    "# Section 2: SHAP explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29596935",
   "metadata": {},
   "source": [
    "For the same learned model, let's explain the model predictions using the SHAP implementation (https://shap.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433a5556",
   "metadata": {},
   "source": [
    "### Initialize the explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a8ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(model, train, feature_perturbation=\"interventional\")\n",
    "shap_values = explainer.shap_values(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and apply to test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f34dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_array = test.to_numpy() # We need to provide the data in dense format, not sparse\n",
    "shap.summary_plot(shap_values, X_test_array, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f003090f",
   "metadata": {},
   "source": [
    "#### SHAP's local explanations\n",
    "\n",
    "For the same test data instance that you chose in Section 1 above (`idx_to_explain`), generate SHAP's explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598c4d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "print(\"Credit risk: Good\" if labels_test[idx_to_explain] else \"Credit risk: Bad\")\n",
    "print(test.iloc[idx_to_explain])\n",
    "shap.force_plot(\n",
    "    explainer.expected_value, shap_values[idx_to_explain,:], X_test_array[idx_to_explain,:],\n",
    "    feature_names=feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a3e49c",
   "metadata": {},
   "source": [
    "#### Q4. Explain the SHAP output above. Which features have the highest contribution toward the outcome?\n",
    "\n",
    "**Your analysis here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4271b7",
   "metadata": {},
   "source": [
    "We can also check the features that contribute to the positive and negative classes in the following manner. Check if what you obtain below is consistent with your observations in Q4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking features that contribute to the positive and negative classification of the instance\n",
    "vals = shap_values[idx_to_explain,:]\n",
    "positive_class_weight = defaultdict(float)\n",
    "negative_class_weight = defaultdict(float)\n",
    "feats = feature_names\n",
    "\n",
    "for feat_i, val_i in zip(feats, vals):\n",
    "  if val_i > 0:\n",
    "    positive_class_weight[feat_i] += val_i\n",
    "  elif val_i < 0:\n",
    "    negative_class_weight[feat_i] += val_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b339ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sorted(positive_class_weight.items(), key=operator.itemgetter(1), reverse=True))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8d7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sorted(negative_class_weight.items(), key=operator.itemgetter(1)))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c794c9",
   "metadata": {},
   "source": [
    "#### Q5. Select another instance and explain its prediction using SHAP. Also, identify the features that have positive and those that have negative contribution toward the outcome. \n",
    "\n",
    "**Your analysis here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53fb982",
   "metadata": {},
   "source": [
    "#### SHAP's Global explanations\n",
    "\n",
    "We can use SHAP to identify features that the model deems important on the entire data by using the `shap.plots.bar()` function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6. Based on the above plot, what can you say about how the trained model makes decisions?\n",
    "\n",
    "**Your analysis here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Comparing SHAP and LIME's explanations\n",
    "In this section, you will compare the explanations generated by SHAP and LIME and comment on their agreement, ease of understanding and stability over different instances.\n",
    "\n",
    "#### Q7. For the same instance (say, `idx_to_explain` above), how do the local explanations generated by SHAP compare to that of LIME?\n",
    "\n",
    "**Your analysis here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea86cd0",
   "metadata": {},
   "source": [
    "#### Q8. Select another instance and compare the local explanations of LIME and SHAP. Do the explanations agree? Did you come across examples where the explanations did not agree with each other. In general, what can you comment about the stability of the explanations generated by the two methods?\n",
    "\n",
    "**Your analysis here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q9. How do the global explanations of SHAP compare with LIME's global explanations?\n",
    "\n",
    "**Your analysis here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd86462",
   "metadata": {},
   "source": [
    "# Section 4: Generating explanations for a non-linear classifier\n",
    "\n",
    "So far in this assignment, you have worked with logistic regression which is a linear classifier. In this section, we will explore SHAP and LIME for a non-linear model such as XGBoost, random forest classifiers or neural networks.  \n",
    "\n",
    "#### Q10. Select a test instance to explain and compare the local explanations over its model predictions using SHAP and LIME. \n",
    "\n",
    "**Your analysis here:**\n",
    "\n",
    "#### Q11. Compare the global explanations for this model as generated by SHAP and LIME. \n",
    "\n",
    "**Your analysis here:**\n",
    "\n",
    "#### Q12. Provide a discussion of how well the two methods (SHAP and LIME) generalize to different models.\n",
    "\n",
    "**Your analysis here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1ed701",
   "metadata": {},
   "source": [
    "# Submitting this Assignment Notebook\n",
    "\n",
    "Once complete, please submit your assignment notebook as an attachment under \\\"Assignments > Assignment 3\\\" on Brightspace. You can download a copy of your notebook using ```File > Download .ipynb```. Please ensure you submit the `.ipynb` file (and not a `.py` file).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677a373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
