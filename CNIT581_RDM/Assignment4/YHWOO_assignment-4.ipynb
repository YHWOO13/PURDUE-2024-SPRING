{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wu8QNsWRb_xp"
   },
   "source": [
    "# Yoonhyuck WOO / Purdue University_Computer and Information Technology\n",
    "# Assignment 4: Detecting and Mitigating Bias \n",
    "# Professor: Dr. Pradhan\n",
    "\n",
    "## Date: 3.4 - 5:00pm 3/22/2024 (EST)\n",
    "\n",
    "#### references\n",
    "- class lectures\n",
    "\n",
    "\n",
    "The goal of this tutorial is to introduce the basic functionality of AI Fairness 360 for detecting and mitigating bias. As before, we will work with the German Credit dataset. There are many metrics one can use to detect the presence of bias. Likewise, there are many different bias mitigation algorithms one can employ. AI Fairness 360 provides some of them most common metrics and algorithms.\n",
    "\n",
    "\n",
    "### Bias mitigation techniques\n",
    "\n",
    "We learnt about the different bias mitigation techniques in class called _pre-processing_, _in-processing_, and _post-processing_.\n",
    "\n",
    "\n",
    "We will use AI Fairness 360 (`aif360`) to detect and mitigate bias. We will look for bias in the creation of a machine learning model that predicts whether an applicant should be given credit based on various features from a typical credit application. The protected attribute will be \"Age\", with \"1\" (older than or equal to 25) and \"0\" (younger than 25) being the values for the _privileged_ and _unprivileged_ groups, respectively.\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "1. Install and import packages and modules\n",
    "2. Load dataset, split between train and test, and compute fairness metrics on original training dataset\n",
    "3. Mitigate bias using a pre-processing algorithm (reweighing)\n",
    "4. Mitigate bias using an in-processing algorithm (adversarial debiasing)\n",
    "5. Mitigate bias using a post-processing algorithm (equalized odds post processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSvZzh_-ntSU"
   },
   "source": [
    "\n",
    "## 1. Import Statements\n",
    "\n",
    "First, we install the necessary packages. Then we import several components from the `aif360` package. We are relying on aif360 for this assignment, so please start early to make sure that the dependencies are resolved and that the pacakges load correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aif360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6.0\n"
     ]
    }
   ],
   "source": [
    "print(aif360.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install aif360[inFairness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow-macos\n",
      "ERROR: No matching distribution found for tensorflow-macos\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-macos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aif360==0.2.2\n",
      "  Using cached aif360-0.2.2-py2.py3-none-any.whl (56.4 MB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lg\\anaconda3\\lib\\site-packages (from aif360==0.2.2) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from aif360==0.2.2) (1.21.4)\n",
      "Requirement already satisfied: pandas>=0.23.3 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from aif360==0.2.2) (2.0.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\lg\\anaconda3\\lib\\site-packages (from aif360==0.2.2) (1.10.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from pandas>=0.23.3->aif360==0.2.2) (2021.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from pandas>=0.23.3->aif360==0.2.2) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from pandas>=0.23.3->aif360==0.2.2) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.23.3->aif360==0.2.2) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from scikit-learn->aif360==0.2.2) (2.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from scikit-learn->aif360==0.2.2) (1.3.2)\n",
      "Installing collected packages: aif360\n",
      "  Attempting uninstall: aif360\n",
      "    Found existing installation: aif360 0.6.0\n",
      "    Uninstalling aif360-0.6.0:\n",
      "      Successfully uninstalled aif360-0.6.0\n",
      "Successfully installed aif360-0.2.2\n"
     ]
    }
   ],
   "source": [
    "# No need to re-install if you already did so in Assignment 2\n",
    "!pip install aif360==0.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aif360==0.6.0\n",
      "  Using cached aif360-0.6.0-py3-none-any.whl (229 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from aif360==0.6.0) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from aif360==0.6.0) (1.10.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from aif360==0.6.0) (2.0.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lg\\anaconda3\\lib\\site-packages (from aif360==0.6.0) (3.3.4)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from aif360==0.6.0) (1.21.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->aif360==0.6.0) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->aif360==0.6.0) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->aif360==0.6.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360==0.6.0) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0->aif360==0.6.0) (2.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0->aif360==0.6.0) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from matplotlib->aif360==0.6.0) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from matplotlib->aif360==0.6.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from matplotlib->aif360==0.6.0) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from matplotlib->aif360==0.6.0) (2.4.7)\n",
      "Installing collected packages: aif360\n",
      "  Attempting uninstall: aif360\n",
      "    Found existing installation: aif360 0.2.2\n",
      "    Uninstalling aif360-0.2.2:\n",
      "      Successfully uninstalled aif360-0.2.2\n",
      "Successfully installed aif360-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install aif360==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3511,
     "status": "ok",
     "timestamp": 1643739518204,
     "user": {
      "displayName": "Aniruddha Chauhan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16209082779696786371"
     },
     "user_tz": 300
    },
    "id": "FJxDwiuVb_xt",
    "outputId": "d87328c1-9c0c-44e2-ee4b-a103556d2bf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aif360[inFairness] in c:\\users\\lg\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from aif360[inFairness]) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from aif360[inFairness]) (1.24.4)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from aif360[inFairness]) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from aif360[inFairness]) (1.3.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lg\\anaconda3\\lib\\site-packages (from aif360[inFairness]) (3.3.4)\n",
      "Collecting skorch\n",
      "  Using cached skorch-0.15.0-py3-none-any.whl (239 kB)\n",
      "Collecting inFairness>=0.2.2\n",
      "  Using cached inFairness-0.2.3-py3-none-any.whl (45 kB)\n",
      "Collecting torch>=1.13.0\n",
      "  Using cached torch-2.2.1-cp38-cp38-win_amd64.whl (198.6 MB)\n",
      "Collecting POT>=0.8.0\n",
      "  Using cached POT-0.9.3-cp38-cp38-win_amd64.whl (294 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->aif360[inFairness]) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->aif360[inFairness]) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->aif360[inFairness]) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360[inFairness]) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0->aif360[inFairness]) (2.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0->aif360[inFairness]) (1.3.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\lg\\anaconda3\\lib\\site-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (2.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lg\\anaconda3\\lib\\site-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (2022.3.0)\n",
      "Collecting typing-extensions>=4.8.0\n",
      "  Using cached typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (2.11.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\lg\\anaconda3\\lib\\site-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (3.6.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\lg\\anaconda3\\lib\\site-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (1.8)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (1.1.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from matplotlib->aif360[inFairness]) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from matplotlib->aif360[inFairness]) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from matplotlib->aif360[inFairness]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from matplotlib->aif360[inFairness]) (0.10.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from networkx->torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (5.0.6)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: tqdm>=4.14.0 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from skorch->aif360[inFairness]) (4.63.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lg\\anaconda3\\lib\\site-packages (from tqdm>=4.14.0->skorch->aif360[inFairness]) (0.4.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lg\\anaconda3\\lib\\site-packages (from sympy->torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (1.2.1)\n",
      "Installing collected packages: typing-extensions, torch, tabulate, POT, skorch, inFairness\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.1.1\n",
      "    Uninstalling typing-extensions-4.1.1:\n",
      "      Successfully uninstalled typing-extensions-4.1.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.1\n",
      "    Uninstalling torch-1.9.1:\n",
      "      Successfully uninstalled torch-1.9.1\n",
      "Successfully installed POT-0.9.3 inFairness-0.2.3 skorch-0.15.0 tabulate-0.9.0 torch-2.2.1 typing-extensions-4.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.10.1 requires torch==1.9.1, but you have torch 2.2.1 which is incompatible.\n",
      "torchtext 0.10.1 requires torch==1.9.1, but you have torch 2.2.1 which is incompatible.\n",
      "torchaudio 0.9.1 requires torch==1.9.1, but you have torch 2.2.1 which is incompatible.\n",
      "allennlp 2.9.2 requires torch<1.12.0,>=1.6.0, but you have torch 2.2.1 which is incompatible.\n",
      "allennlp 2.9.2 requires transformers<4.18,>=4.1, but you have transformers 4.18.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# import all necessary packages\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from numba import jit\n",
    "from aif360.datasets import GermanDataset, BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, DatasetMetric\n",
    "\n",
    "from aif360.algorithms.preprocessing import Reweighing, LFR, DisparateImpactRemover\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "\n",
    "from aif360.explainers import MetricTextExplainer, MetricJSONExplainer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQj5VqOSb_xt"
   },
   "source": [
    "## 2. Load Data, Specify Protected Attribute, and Split Data\n",
    "\n",
    "We will use the German Credit data, set the protected attribute to be age, create two variables to represent the privileged and unprivileged groups, and split the original dataset into training and test data subsets. Finally, we will build a typical machine learning workflow that involves training a machine learning model on the training dataset and use a test dataset to assess the model's efficacy (e.g., accuracy, fairness). For this dataset, we have a binary classification problem that predicts individuals as being a good or a bad credit risk.\n",
    "\n",
    "In this dataset, we consider older applicants (`age >= 25`) as the privileged group and younger applicants (`age < 25`) as the unprivileged group. \n",
    "\n",
    "We will use the preprocessed GermanDataset with one-hot encoded data provided by the aif360 package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1643739518204,
     "user": {
      "displayName": "Aniruddha Chauhan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16209082779696786371"
     },
     "user_tz": 300
    },
    "id": "JYB3PkStb_xv",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\LG\\\\anaconda3\\\\lib\\\\site-packages\\\\aif360\\\\datasets\\\\..\\\\data\\\\raw\\\\german\\\\german.data'\n",
      "To use this class, please download the following files:\n",
      "\n",
      "\thttps://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\n",
      "\thttps://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\n",
      "\n",
      "and place them, as-is, in the folder:\n",
      "\n",
      "\tC:\\Users\\LG\\anaconda3\\lib\\site-packages\\aif360\\data\\raw\\german\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\anaconda3\\lib\\site-packages\\aif360\\datasets\\german_dataset.py\", line 78, in __init__\n",
      "    df = pd.read_csv(filepath, sep=' ', header=None, names=column_names,\n",
      "  File \"C:\\Users\\LG\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 912, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"C:\\Users\\LG\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 577, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"C:\\Users\\LG\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1407, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"C:\\Users\\LG\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1661, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"C:\\Users\\LG\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\", line 859, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\LG\\\\anaconda3\\\\lib\\\\site-packages\\\\aif360\\\\datasets\\\\..\\\\data\\\\raw\\\\german\\\\german.data'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-3a617b233b76>\", line 3, in <module>\n",
      "    gd = GermanDataset(protected_attribute_names=['sex'],\n",
      "  File \"C:\\Users\\LG\\anaconda3\\lib\\site-packages\\aif360\\datasets\\german_dataset.py\", line 89, in __init__\n",
      "    sys.exit(1)\n",
      "SystemExit: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\LG\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\LG\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\LG\\anaconda3\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\aif360\\datasets\\german_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             df = pd.read_csv(filepath, sep=' ', header=None, names=column_names,\n\u001b[0m\u001b[0;32m     79\u001b[0m                              na_values=na_values)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"b\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1661\u001b[1;33m             self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\LG\\\\anaconda3\\\\lib\\\\site-packages\\\\aif360\\\\datasets\\\\..\\\\data\\\\raw\\\\german\\\\german.data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-3a617b233b76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprotected_attribute_maps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Male'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Female'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m gd = GermanDataset(protected_attribute_names=['sex'],\n\u001b[0m\u001b[0;32m      4\u001b[0m                    \u001b[0mprivileged_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'male'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\aif360\\datasets\\german_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2052\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[0;32m   2053\u001b[0m                            'the full traceback.\\n']\n\u001b[1;32m-> 2054\u001b[1;33m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[0;32m   2055\u001b[0m                                                                      value))\n\u001b[0;32m   2056\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \"\"\"\n\u001b[1;32m--> 754\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m             out_list = (\n\u001b[1;32m--> 629\u001b[1;33m                 self.structured_traceback(\n\u001b[0m\u001b[0;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0metb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "label_map = {1.0: 'Good Credit', 0.0: 'Bad Credit'}\n",
    "protected_attribute_maps = [{1.0: 'Male', 0.0: 'Female'}]\n",
    "gd = GermanDataset(protected_attribute_names=['sex'],\n",
    "                   privileged_classes=[['male']], \n",
    "                   metadata={'label_map': label_map, 'protected_attribute_maps': protected_attribute_maps})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd2 = GermanDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               instance weights features                \\\n",
      "                                                         \n",
      "                                   month credit_amount   \n",
      "instance names                                           \n",
      "0                           1.0      6.0        1169.0   \n",
      "1                           1.0     48.0        5951.0   \n",
      "2                           1.0     12.0        2096.0   \n",
      "3                           1.0     42.0        7882.0   \n",
      "4                           1.0     24.0        4870.0   \n",
      "...                         ...      ...           ...   \n",
      "995                         1.0     12.0        1736.0   \n",
      "996                         1.0     30.0        3857.0   \n",
      "997                         1.0     12.0         804.0   \n",
      "998                         1.0     45.0        1845.0   \n",
      "999                         1.0     45.0        4576.0   \n",
      "\n",
      "                                                                \\\n",
      "                                                                 \n",
      "               investment_as_income_percentage residence_since   \n",
      "instance names                                                   \n",
      "0                                          4.0             4.0   \n",
      "1                                          2.0             2.0   \n",
      "2                                          2.0             3.0   \n",
      "3                                          2.0             4.0   \n",
      "4                                          3.0             4.0   \n",
      "...                                        ...             ...   \n",
      "995                                        3.0             4.0   \n",
      "996                                        4.0             4.0   \n",
      "997                                        4.0             4.0   \n",
      "998                                        4.0             4.0   \n",
      "999                                        3.0             4.0   \n",
      "\n",
      "                                                                        \\\n",
      "               protected attribute                                       \n",
      "                               age number_of_credits people_liable_for   \n",
      "instance names                                                           \n",
      "0                              1.0               2.0               1.0   \n",
      "1                              0.0               1.0               1.0   \n",
      "2                              1.0               1.0               2.0   \n",
      "3                              1.0               1.0               2.0   \n",
      "4                              1.0               2.0               2.0   \n",
      "...                            ...               ...               ...   \n",
      "995                            1.0               1.0               1.0   \n",
      "996                            1.0               1.0               1.0   \n",
      "997                            1.0               1.0               1.0   \n",
      "998                            0.0               1.0               1.0   \n",
      "999                            1.0               1.0               1.0   \n",
      "\n",
      "                                               ...               \\\n",
      "               protected attribute             ...                \n",
      "                               sex status=A11  ... housing=A153   \n",
      "instance names                                 ...                \n",
      "0                              1.0        1.0  ...          0.0   \n",
      "1                              0.0        0.0  ...          0.0   \n",
      "2                              1.0        0.0  ...          0.0   \n",
      "3                              1.0        1.0  ...          1.0   \n",
      "4                              1.0        1.0  ...          1.0   \n",
      "...                            ...        ...  ...          ...   \n",
      "995                            0.0        0.0  ...          0.0   \n",
      "996                            1.0        1.0  ...          0.0   \n",
      "997                            1.0        0.0  ...          0.0   \n",
      "998                            1.0        1.0  ...          1.0   \n",
      "999                            1.0        0.0  ...          0.0   \n",
      "\n",
      "                                                                   \\\n",
      "                                                                    \n",
      "               skill_level=A171 skill_level=A172 skill_level=A173   \n",
      "instance names                                                      \n",
      "0                           0.0              0.0              1.0   \n",
      "1                           0.0              0.0              1.0   \n",
      "2                           0.0              1.0              0.0   \n",
      "3                           0.0              0.0              1.0   \n",
      "4                           0.0              0.0              1.0   \n",
      "...                         ...              ...              ...   \n",
      "995                         0.0              1.0              0.0   \n",
      "996                         0.0              0.0              0.0   \n",
      "997                         0.0              0.0              1.0   \n",
      "998                         0.0              0.0              1.0   \n",
      "999                         0.0              0.0              1.0   \n",
      "\n",
      "                                                               \\\n",
      "                                                                \n",
      "               skill_level=A174 telephone=A191 telephone=A192   \n",
      "instance names                                                  \n",
      "0                           0.0            0.0            1.0   \n",
      "1                           0.0            1.0            0.0   \n",
      "2                           0.0            1.0            0.0   \n",
      "3                           0.0            1.0            0.0   \n",
      "4                           0.0            1.0            0.0   \n",
      "...                         ...            ...            ...   \n",
      "995                         0.0            1.0            0.0   \n",
      "996                         1.0            0.0            1.0   \n",
      "997                         0.0            1.0            0.0   \n",
      "998                         0.0            0.0            1.0   \n",
      "999                         0.0            1.0            0.0   \n",
      "\n",
      "                                                       labels  \n",
      "                                                               \n",
      "               foreign_worker=A201 foreign_worker=A202         \n",
      "instance names                                                 \n",
      "0                              1.0                 0.0    1.0  \n",
      "1                              1.0                 0.0    2.0  \n",
      "2                              1.0                 0.0    1.0  \n",
      "3                              1.0                 0.0    1.0  \n",
      "4                              1.0                 0.0    2.0  \n",
      "...                            ...                 ...    ...  \n",
      "995                            1.0                 0.0    1.0  \n",
      "996                            1.0                 0.0    1.0  \n",
      "997                            1.0                 0.0    1.0  \n",
      "998                            1.0                 0.0    2.0  \n",
      "999                            1.0                 0.0    1.0  \n",
      "\n",
      "[1000 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "print(gd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b6323a4d8663>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# note that we drop sex, which may also be a protected attribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m dataset_orig_2 = GermanDataset(protected_attribute_names=['sex'],\n\u001b[0m\u001b[0;32m      3\u001b[0m                              privileged_classes=['male'])\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# df['sex'] = df['personal_status'].replace(status_map)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\aif360\\datasets\\german_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         super(GermanDataset, self).__init__(df=df, label_name=label_name,\n\u001b[0m\u001b[0;32m     92\u001b[0m             \u001b[0mfavorable_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfavorable_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0mprotected_attribute_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotected_attribute_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\aif360\\datasets\\standard_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, df, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, scores_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;31m# find all instances which match any of the favorable classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             pos = np.logical_or.reduce(np.equal.outer(favorable_classes,\n\u001b[0m\u001b[0;32m    142\u001b[0m                                                       df[label_name]))\n\u001b[0;32m    143\u001b[0m             \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfavorable_label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2015\u001b[0m     ):\n\u001b[1;32m-> 2016\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marraylike\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_ufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2018\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[1;31m# e.g. np.negative (only one reached), with \"where\" and \"out\" in kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36mreconstruct\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"outer\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# note that we drop sex, which may also be a protected attribute\n",
    "dataset_orig_2 = GermanDataset(protected_attribute_names=['sex'],\n",
    "                             privileged_classes=['male'])\n",
    "# df['sex'] = df['personal_status'].replace(status_map)\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig_2.split([0.7], shuffle=True)\n",
    "\n",
    "# privileged_groups = [{'age': 1}]\n",
    "# unprivileged_groups = [{'age': 0}]\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: could not convert string to float: 'male'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame values must be numerical.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\aif360\\datasets\\structured_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, df, label_names, protected_attribute_names, instance_weights_name, scores_names, unprivileged_protected_attributes, privileged_protected_attributes, metadata)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6323\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6324\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6325\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         return self.apply(\n\u001b[0m\u001b[0;32m    452\u001b[0m             \u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py\u001b[0m in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_astype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py\u001b[0m in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'male'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4505e89b3b50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m german_data = GermanDataset(protected_attribute_names=['age'],\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprivileged_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     features_to_drop=['personal_status'])\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# german_data.drop(['sex', 'age'], axis=1, inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\aif360\\datasets\\german_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         super(GermanDataset, self).__init__(df=df, label_name=label_name,\n\u001b[0m\u001b[0;32m     92\u001b[0m             \u001b[0mfavorable_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfavorable_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0mprotected_attribute_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotected_attribute_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\aif360\\datasets\\standard_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, df, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, scores_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munfavorable_label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         super(StandardDataset, self).__init__(df=df, label_names=[label_name],\n\u001b[0m\u001b[0;32m    147\u001b[0m             \u001b[0mprotected_attribute_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotected_attribute_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[0mprivileged_protected_attributes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprivileged_protected_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\aif360\\datasets\\binary_label_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, favorable_label, unfavorable_label, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munfavorable_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munfavorable_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBinaryLabelDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvalidate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\aif360\\datasets\\structured_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, df, label_names, protected_attribute_names, instance_weights_name, scores_names, unprivileged_protected_attributes, privileged_protected_attributes, metadata)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ValueError: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DataFrame values must be numerical.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;31m# Convert all column names to strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame values must be numerical."
     ]
    }
   ],
   "source": [
    "german_data = GermanDataset(protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x > 25],\n",
    "    features_to_drop=['personal_status'])\n",
    "\n",
    "# german_data.drop(['sex', 'age'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_mappings = {\n",
    "    'label_maps': [{1.0: 'Good Credit', 2.0: 'Bad Credit'}],\n",
    "    'protected_attribute_maps': [{1.0: 'Male', 0.0: 'Female'},\n",
    "                                 {1.0: 'Old', 0.0: 'Young'}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that we drop sex, which may also be a protected attribute\n",
    "dataset_orig = GermanDataset(protected_attribute_names=['age'],\n",
    "                             privileged_classes=[lambda x: x >= 25],\n",
    "                             features_to_drop=['personal_status', 'sex'])\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1643739518205,
     "user": {
      "displayName": "Aniruddha Chauhan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16209082779696786371"
     },
     "user_tz": 300
    },
    "id": "MsFiFKReb_xw",
    "outputId": "ab4ceeb1-3ede-4ad3-d21f-7aa2816a3a29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape:  (1000, 57)\n",
      "Train dataset shape:  (700, 57)\n",
      "Test dataset shape:  (300, 57)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original data shape: \",dataset_orig.features.shape)\n",
    "print(\"Train dataset shape: \", dataset_orig_train.features.shape)\n",
    "print(\"Test dataset shape: \", dataset_orig_test.features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object ```dataset_orig``` is an aif360 dataset, which has some useful methods and attributes that you can explore. More documentation is available at https://aif360.readthedocs.io/en/latest/modules/datasets.html. \n",
    "For now, we'll just transform the data into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1643739518206,
     "user": {
      "displayName": "Aniruddha Chauhan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16209082779696786371"
     },
     "user_tz": 300
    },
    "id": "W3Aonmt3b_xw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (1000, 58)\n"
     ]
    }
   ],
   "source": [
    "df, dict_df = dataset_orig.convert_to_dataframe()\n",
    "print(\"Shape: \", df.shape)\n",
    "# print(df.columns)\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>investment_as_income_percentage</th>\n",
       "      <th>residence_since</th>\n",
       "      <th>age</th>\n",
       "      <th>number_of_credits</th>\n",
       "      <th>people_liable_for</th>\n",
       "      <th>status=A11</th>\n",
       "      <th>status=A12</th>\n",
       "      <th>status=A13</th>\n",
       "      <th>...</th>\n",
       "      <th>housing=A153</th>\n",
       "      <th>skill_level=A171</th>\n",
       "      <th>skill_level=A172</th>\n",
       "      <th>skill_level=A173</th>\n",
       "      <th>skill_level=A174</th>\n",
       "      <th>telephone=A191</th>\n",
       "      <th>telephone=A192</th>\n",
       "      <th>foreign_worker=A201</th>\n",
       "      <th>foreign_worker=A202</th>\n",
       "      <th>credit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.0</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  credit_amount  investment_as_income_percentage  residence_since  \\\n",
       "0    6.0         1169.0                              4.0              4.0   \n",
       "1   48.0         5951.0                              2.0              2.0   \n",
       "2   12.0         2096.0                              2.0              3.0   \n",
       "3   42.0         7882.0                              2.0              4.0   \n",
       "4   24.0         4870.0                              3.0              4.0   \n",
       "\n",
       "   age  number_of_credits  people_liable_for  status=A11  status=A12  \\\n",
       "0  1.0                2.0                1.0         1.0         0.0   \n",
       "1  0.0                1.0                1.0         0.0         1.0   \n",
       "2  1.0                1.0                2.0         0.0         0.0   \n",
       "3  1.0                1.0                2.0         1.0         0.0   \n",
       "4  1.0                2.0                2.0         1.0         0.0   \n",
       "\n",
       "   status=A13  ...  housing=A153  skill_level=A171  skill_level=A172  \\\n",
       "0         0.0  ...           0.0               0.0               0.0   \n",
       "1         0.0  ...           0.0               0.0               0.0   \n",
       "2         0.0  ...           0.0               0.0               1.0   \n",
       "3         0.0  ...           1.0               0.0               0.0   \n",
       "4         0.0  ...           1.0               0.0               0.0   \n",
       "\n",
       "   skill_level=A173  skill_level=A174  telephone=A191  telephone=A192  \\\n",
       "0               1.0               0.0             0.0             1.0   \n",
       "1               1.0               0.0             1.0             0.0   \n",
       "2               0.0               0.0             1.0             0.0   \n",
       "3               1.0               0.0             1.0             0.0   \n",
       "4               1.0               0.0             1.0             0.0   \n",
       "\n",
       "   foreign_worker=A201  foreign_worker=A202  credit  \n",
       "0                  1.0                  0.0     1.0  \n",
       "1                  1.0                  0.0     2.0  \n",
       "2                  1.0                  0.0     1.0  \n",
       "3                  1.0                  0.0     1.0  \n",
       "4                  1.0                  0.0     2.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_names': ['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202'], 'label_names': ['credit'], 'protected_attribute_names': ['age'], 'instance_names': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '450', '451', '452', '453', '454', '455', '456', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '478', '479', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '500', '501', '502', '503', '504', '505', '506', '507', '508', '509', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570', '571', '572', '573', '574', '575', '576', '577', '578', '579', '580', '581', '582', '583', '584', '585', '586', '587', '588', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613', '614', '615', '616', '617', '618', '619', '620', '621', '622', '623', '624', '625', '626', '627', '628', '629', '630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '640', '641', '642', '643', '644', '645', '646', '647', '648', '649', '650', '651', '652', '653', '654', '655', '656', '657', '658', '659', '660', '661', '662', '663', '664', '665', '666', '667', '668', '669', '670', '671', '672', '673', '674', '675', '676', '677', '678', '679', '680', '681', '682', '683', '684', '685', '686', '687', '688', '689', '690', '691', '692', '693', '694', '695', '696', '697', '698', '699', '700', '701', '702', '703', '704', '705', '706', '707', '708', '709', '710', '711', '712', '713', '714', '715', '716', '717', '718', '719', '720', '721', '722', '723', '724', '725', '726', '727', '728', '729', '730', '731', '732', '733', '734', '735', '736', '737', '738', '739', '740', '741', '742', '743', '744', '745', '746', '747', '748', '749', '750', '751', '752', '753', '754', '755', '756', '757', '758', '759', '760', '761', '762', '763', '764', '765', '766', '767', '768', '769', '770', '771', '772', '773', '774', '775', '776', '777', '778', '779', '780', '781', '782', '783', '784', '785', '786', '787', '788', '789', '790', '791', '792', '793', '794', '795', '796', '797', '798', '799', '800', '801', '802', '803', '804', '805', '806', '807', '808', '809', '810', '811', '812', '813', '814', '815', '816', '817', '818', '819', '820', '821', '822', '823', '824', '825', '826', '827', '828', '829', '830', '831', '832', '833', '834', '835', '836', '837', '838', '839', '840', '841', '842', '843', '844', '845', '846', '847', '848', '849', '850', '851', '852', '853', '854', '855', '856', '857', '858', '859', '860', '861', '862', '863', '864', '865', '866', '867', '868', '869', '870', '871', '872', '873', '874', '875', '876', '877', '878', '879', '880', '881', '882', '883', '884', '885', '886', '887', '888', '889', '890', '891', '892', '893', '894', '895', '896', '897', '898', '899', '900', '901', '902', '903', '904', '905', '906', '907', '908', '909', '910', '911', '912', '913', '914', '915', '916', '917', '918', '919', '920', '921', '922', '923', '924', '925', '926', '927', '928', '929', '930', '931', '932', '933', '934', '935', '936', '937', '938', '939', '940', '941', '942', '943', '944', '945', '946', '947', '948', '949', '950', '951', '952', '953', '954', '955', '956', '957', '958', '959', '960', '961', '962', '963', '964', '965', '966', '967', '968', '969', '970', '971', '972', '973', '974', '975', '976', '977', '978', '979', '980', '981', '982', '983', '984', '985', '986', '987', '988', '989', '990', '991', '992', '993', '994', '995', '996', '997', '998', '999'], 'instance_weights': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'privileged_protected_attributes': [array([1.])], 'unprivileged_protected_attributes': [array([0.])]}\n"
     ]
    }
   ],
   "source": [
    "print(dict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'personal_status'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3653\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3654\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'personal_status'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e65e68970c3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'personal_status'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3761\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3762\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3654\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3655\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3656\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3657\u001b[0m             \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'personal_status'"
     ]
    }
   ],
   "source": [
    "df['personal_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kITY3AtDb_xz"
   },
   "source": [
    "## 3. Compute Fairness Metrics on Original Training Data\n",
    "Now that we have identified the protected attribute \"age\" and defined privileged and unprivileged values, we can use aif360 to detect bias in the dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZLVzqlmwOXI"
   },
   "source": [
    "### Mean Outcomes\n",
    "\n",
    "Compare the base rates (i.e., percentage of favorable results) for the privileged and unprivileged groups and report the difference (unprivileged base rate - privileged base rate). This is implemented in the ```mean_difference``` method on the BinaryLabelDatasetMetric class, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1643739519124,
     "user": {
      "displayName": "Aniruddha Chauhan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16209082779696786371"
     },
     "user_tz": 300
    },
    "id": "bVQWXC8Ub_x0",
    "outputId": "ae13c1db-2647-4764-ddf9-e2274a93dcbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training dataset\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.169905\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(\n",
    "     dataset_orig_train, \n",
    "     unprivileged_groups=unprivileged_groups,\n",
    "     privileged_groups=privileged_groups\n",
    "  )\n",
    "print(\"Original training dataset\")\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZufOXh9b_x0"
   },
   "source": [
    "### Disparate Impact\n",
    "We can calculate the ratio of (predicted) favorable outcomes for the unprivileged group compared to the privileged group as implemented in the ```disparate_impact``` method on the BinaryLabelDatasetMetric class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1643739519126,
     "user": {
      "displayName": "Aniruddha Chauhan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16209082779696786371"
     },
     "user_tz": 300
    },
    "id": "1iw7g6Hjb_x0",
    "outputId": "d5efcc0a-5d2c-4120-94ab-2e8dbe658fc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training dataset\n",
      "Disparate Impact = 0.766430\n"
     ]
    }
   ],
   "source": [
    "print(\"Original training dataset\")\n",
    "print(\"Disparate Impact = %f\" % metric_orig_train.disparate_impact())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The fairness metrics above will vary depending upon the train-test split. If the magnitude of mean difference is less than 10%, try another split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcTiGnSob_x1"
   },
   "source": [
    "### Built-In Explainers\n",
    "\n",
    "```aif360``` has some useful explainers for the fairness metrics which can be used to interpret the fairness metric values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1643739519127,
     "user": {
      "displayName": "Aniruddha Chauhan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16209082779696786371"
     },
     "user_tz": 300
    },
    "id": "ERMXmj2pb_x1"
   },
   "outputs": [],
   "source": [
    "json_expl = MetricJSONExplainer(metric_orig_train)\n",
    "def format_json(json_str):\n",
    "    return json.dumps(json.loads(json_str, object_pairs_hook=OrderedDict),\n",
    "                      indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWuosH5pxVHe"
   },
   "source": [
    "Let's print the mean difference explainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1643739519128,
     "user": {
      "displayName": "Aniruddha Chauhan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16209082779696786371"
     },
     "user_tz": 300
    },
    "id": "7cc0pIUPxdFl",
    "outputId": "86acf8f0-f04d-4c19-ec4a-3ba6d0d6fd9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metric\": \"Mean Difference\",\n",
      "  \"message\": \"Mean difference (mean label value on privileged instances - mean label value on unprivileged instances): -0.1699054740619017\",\n",
      "  \"numPositivesUnprivileged\": 63.0,\n",
      "  \"numInstancesUnprivileged\": 113.0,\n",
      "  \"numPositivesPrivileged\": 427.0,\n",
      "  \"numInstancesPrivileged\": 587.0,\n",
      "  \"description\": \"Computed as the difference of the rate of favorable outcomes received by the unprivileged group to the privileged group.\",\n",
      "  \"ideal\": \"The ideal value of this metric is 0.0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(format_json(json_expl.mean_difference()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vl-r2vpjxPFo"
   },
   "source": [
    "We can also print the disparate impact explainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1643739519129,
     "user": {
      "displayName": "Aniruddha Chauhan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16209082779696786371"
     },
     "user_tz": 300
    },
    "id": "y-FoLzMTxSGS",
    "outputId": "8c66b2d1-0262-48c6-a17d-12c871f04c85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metric\": \"Disparate Impact\",\n",
      "  \"message\": \"Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.7664297113013201\",\n",
      "  \"numPositivePredictionsUnprivileged\": 63.0,\n",
      "  \"numUnprivileged\": 113.0,\n",
      "  \"numPositivePredictionsPrivileged\": 427.0,\n",
      "  \"numPrivileged\": 587.0,\n",
      "  \"description\": \"Computed as the ratio of rate of favorable outcome for the unprivileged group to that of the privileged group.\",\n",
      "  \"ideal\": \"The ideal value of this metric is 1.0 A value < 1 implies higher benefit for the privileged group and a value >1 implies a higher benefit for the unprivileged group.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(format_json(json_expl.disparate_impact()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcDleSrDJr_B"
   },
   "source": [
    "**Q1:** Using the explainers above, interpret the difference in means and disparate impact in the German Credit data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HV2t23yJ19P"
   },
   "source": [
    "**Q1_Write your interpretation here**\n",
    "\n",
    "- statistical parity: If the values are less than 0, the privileged group has a higher proportion of predicted positive outcomes than the unprivileged group \n",
    "\n",
    "- Disparate Imapct: If the values are less than 1, the same is true when statistical parity values are less than 0, which means positive bias.\n",
    "\n",
    "Thus, both metrics have similar meanings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model on the training data\n",
    "\n",
    "Let's build a logistic regression model on this training data, predict credit risk for test data and compute the same fairness metrics over the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "\n",
    "df_test, dict_df_test = dataset_orig_test.convert_to_dataframe()\n",
    "df_train, dict_df_train = dataset_orig_train.convert_to_dataframe()\n",
    "\n",
    "# Fit the model to the training data\n",
    "x_train = df_train.drop(['credit'], axis=1)\n",
    "y_train = df_train['credit']\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "x_test = df_test.drop(['credit'], axis=1)\n",
    "y_test = df_test['credit']\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "dataset_pred_test = dataset_orig_test.copy()\n",
    "dataset_pred_test.labels = y_pred.copy()\n",
    "\n",
    "metric_dataset_test = BinaryLabelDatasetMetric(\n",
    "    dataset_pred_test, \n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here to compute fairness metrics\n",
    "json_expl_q2 = MetricJSONExplainer(metric_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metric\": \"Mean Difference\",\n",
      "  \"message\": \"Mean difference (mean label value on privileged instances - mean label value on unprivileged instances): -0.12521343198634033\",\n",
      "  \"numPositivesUnprivileged\": 21.0,\n",
      "  \"numInstancesUnprivileged\": 49.0,\n",
      "  \"numPositivesPrivileged\": 139.0,\n",
      "  \"numInstancesPrivileged\": 251.0,\n",
      "  \"description\": \"Computed as the difference of the rate of favorable outcomes received by the unprivileged group to the privileged group.\",\n",
      "  \"ideal\": \"The ideal value of this metric is 0.0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(format_json(json_expl_q2.mean_difference()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metric\": \"Disparate Impact\",\n",
      "  \"message\": \"Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.7738951695786228\",\n",
      "  \"numPositivePredictionsUnprivileged\": 21.0,\n",
      "  \"numUnprivileged\": 49.0,\n",
      "  \"numPositivePredictionsPrivileged\": 139.0,\n",
      "  \"numPrivileged\": 251.0,\n",
      "  \"description\": \"Computed as the ratio of rate of favorable outcome for the unprivileged group to that of the privileged group.\",\n",
      "  \"ideal\": \"The ideal value of this metric is 1.0 A value < 1 implies higher benefit for the privileged group and a value >1 implies a higher benefit for the unprivileged group.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(format_json(json_expl_q2.disparate_impact()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** Using the fairness metric functions as before, report the bias observed in the model's predictions over test data. What do these values indicate? Are the model's predictions more biased or less biased compared to the bias observed in the training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2_Write your answer here**\n",
    "\n",
    "As before, both metrics show that the privileged group has a higher proportion of predicted positive outcomes than the unprivileged group, so there is a positive bias.\n",
    "\n",
    "|      | Original data | Model's Predictions over test data   |\n",
    "| :---        |    :----:   |          ---: |\n",
    "| **Mean difference**  | -0.115       | -0.1252   |\n",
    "| **Disparate Impact**   | 0.8477       | 0.7738      |\n",
    "\n",
    "According to the above crosstab, both values of original data are closer to the ideal value, so the model predicts less bias in original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bias Mitigation Techniques\n",
    "\n",
    "We learnt in class that there are several bias mitigation techniques namely, pre-processing, in-processing, and post-processing algorithms.\n",
    "\n",
    "_Pre-processing_ bias mitigation is performed at the data end, before the creation of the model. In other words, we transform the data such that a model learned on the transformed data produces less biased decisions.\n",
    "\n",
    "_In-processing_ bias mitigation methods focus on the model training stage, as compared to pre-processing which focuses on transforming the data prior to model training. This suite of methods includes incorporating a fairness constraint during model training, tweaking the model's objective function, and adversarial learning.\n",
    "\n",
    "_Post-processing_ bias mitigation focus on the model predictions after the model has been trained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQIwiWcKb_x3"
   },
   "source": [
    "### 4.1 Bias Mitigation via Pre-Processing\n",
    "\n",
    "AI Fairness 360 implements several pre-processing mitigation algorithms. We will use the **reweighing algorithm**, which is implemented in the `Reweighing` class in the `aif360.algorithms.preprocessing` package. As discussed in class, this algorithm will transform the dataset by assigning weights to instances in each (group, label) combination to change the base rates and ensure fairness before classification. The idea is to apply appropriate weights to different tuples in the training data to reduce discrimination with respect to the protected attributes.\n",
    "\n",
    "You can find documentation for reweighting here:\n",
    "https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.preprocessing.Reweighing.html \n",
    "\n",
    "Call the fit and transform methods to perform the transformation, producing a newly transformed training dataset (```dataset_transf_train```):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1643739523669,
     "user": {
      "displayName": "Aniruddha Chauhan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16209082779696786371"
     },
     "user_tz": 300
    },
    "id": "CqBmaYXab_x3"
   },
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "dataset_transf_train = RW.fit_transform(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdkCX8Fd0zgN"
   },
   "source": [
    "We can print the weights. Each observation in the data should have a weight. For brevity, let's look at the weights for the first 10 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1643739523669,
     "user": {
      "displayName": "Aniruddha Chauhan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16209082779696786371"
     },
     "user_tz": 300
    },
    "id": "l5ISRhOwb_x3",
    "outputId": "032e2735-51a6-42c7-9e07-07d669cbcd5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.06705539, 0.9782403 , 0.9782403 , 0.9782403 , 0.9782403 ,\n",
       "       0.9782403 , 1.06705539, 0.9782403 , 1.15401786, 0.9782403 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_transf_train.instance_weights)\n",
    "dataset_transf_train.instance_weights[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2k6wrI5Ab_x4"
   },
   "source": [
    "### Compute Fairness Metrics in Transformed Data\n",
    "\n",
    "We can check how effective the transformed data was in removing bias by calculating the metrics used for the original training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_rw_train = BinaryLabelDatasetMetric(\n",
    "    dataset_transf_train, \n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFZh_-La6Eq8"
   },
   "source": [
    "Print the difference in mean outcomes and disparate impact in the transformed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1643739523848,
     "user": {
      "displayName": "Aniruddha Chauhan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16209082779696786371"
     },
     "user_tz": 300
    },
    "id": "gim6DapUb_x4"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "# write code here to compute fairness metrics\n",
    "json_expl_q3 = MetricJSONExplainer(metric_rw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metric\": \"Disparate Impact\",\n",
      "  \"message\": \"Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.9999999999999999\",\n",
      "  \"numPositivePredictionsUnprivileged\": 73.85714285714288,\n",
      "  \"numUnprivileged\": 100.00000000000003,\n",
      "  \"numPositivePredictionsPrivileged\": 443.1428571428572,\n",
      "  \"numPrivileged\": 600.0,\n",
      "  \"description\": \"Computed as the ratio of rate of favorable outcome for the unprivileged group to that of the privileged group.\",\n",
      "  \"ideal\": \"The ideal value of this metric is 1.0 A value < 1 implies higher benefit for the privileged group and a value >1 implies a higher benefit for the unprivileged group.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(format_json(json_expl_q3.disparate_impact()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metric\": \"Mean Difference\",\n",
      "  \"message\": \"Mean difference (mean label value on privileged instances - mean label value on unprivileged instances): -1.1102230246251565e-16\",\n",
      "  \"numPositivesUnprivileged\": 73.85714285714288,\n",
      "  \"numInstancesUnprivileged\": 100.00000000000003,\n",
      "  \"numPositivesPrivileged\": 443.1428571428572,\n",
      "  \"numInstancesPrivileged\": 600.0,\n",
      "  \"description\": \"Computed as the difference of the rate of favorable outcomes received by the unprivileged group to the privileged group.\",\n",
      "  \"ideal\": \"The ideal value of this metric is 0.0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(format_json(json_expl_q3.mean_difference()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1NdOcvCFmC8"
   },
   "source": [
    "**Q3:** How do these values compare to the difference in mean outcomes and disparate impact in the original data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aG_Glh7Frbc"
   },
   "source": [
    "**Q3_Write your answer in this text cell:**\n",
    "\n",
    "|      | Original Data | Reweighing Data   | Model's Predictions over test data   |\n",
    "| :---        |    :----:   |          ---: |         ---: |\n",
    "| **Mean difference**  | -0.115       | -1.110   | -0.1252   |\n",
    "| **Disparate Impact**   | 0.8477       | 0.9999      | 0.7738      |\n",
    "\n",
    "It is fascinating. While the disparate impact of reweighing data is almost ideal, the mean difference is more biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Fairness Metrics on Model Trained on Transformed Data\n",
    "\n",
    "In the following, we will train a model on the transformed data and compute the metrics over predictions made on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4:**  How do you expect the fairness metrics would be over a model trained on the transformed data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4_Write your answer in this text cell:**\n",
    "\n",
    "Even if the fairness metrics over reweighing data show differently, I expect the model's predictions over transformed data will show similarly as before because, according to Q2, fairness metrics on the model's predictions show farther from the ideal value than the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the instances now have weights, we will use a classifier that can incorporate instance weights. In this case, we will use a Naive Bayes classifier (more details here: https://scikit-learn.org/stable/modules/naive_bayes.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_rw, dict_df_train_rw = dataset_transf_train.convert_to_dataframe()\n",
    "\n",
    "# Fit the model to the transformed training data\n",
    "x_train_rw = df_train_rw.drop(['credit'], axis=1)\n",
    "y_train_rw = df_train_rw['credit']\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model__gnb = GaussianNB()\n",
    "model__gnb.fit(x_train_rw, y_train_rw)\n",
    "\n",
    "# Use the model to make predictions on the test data\n",
    "y_pred_rw = model__gnb.predict(x_test)\n",
    "\n",
    "dataset_pred_test_rw = dataset_orig_test.copy()\n",
    "dataset_pred_test_rw.labels = y_pred_rw.copy()\n",
    "\n",
    "# Construct the BinaryLabelDatasetMetric object over the test predictions\n",
    "metric_dataset_test_rw = BinaryLabelDatasetMetric(\n",
    "    dataset_pred_test_rw, \n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print fairness metrics computed over test predictions\n",
    "# write code here\n",
    "json_expl_q5 = MetricJSONExplainer(metric_dataset_test_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metric\": \"Disparate Impact\",\n",
      "  \"message\": \"Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.8597117168545739\",\n",
      "  \"numPositivePredictionsUnprivileged\": 24.0,\n",
      "  \"numUnprivileged\": 49.0,\n",
      "  \"numPositivePredictionsPrivileged\": 143.0,\n",
      "  \"numPrivileged\": 251.0,\n",
      "  \"description\": \"Computed as the ratio of rate of favorable outcome for the unprivileged group to that of the privileged group.\",\n",
      "  \"ideal\": \"The ideal value of this metric is 1.0 A value < 1 implies higher benefit for the privileged group and a value >1 implies a higher benefit for the unprivileged group.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(format_json(json_expl_q5.disparate_impact()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metric\": \"Mean Difference\",\n",
      "  \"message\": \"Mean difference (mean label value on privileged instances - mean label value on unprivileged instances): -0.07992519717050173\",\n",
      "  \"numPositivesUnprivileged\": 24.0,\n",
      "  \"numInstancesUnprivileged\": 49.0,\n",
      "  \"numPositivesPrivileged\": 143.0,\n",
      "  \"numInstancesPrivileged\": 251.0,\n",
      "  \"description\": \"Computed as the difference of the rate of favorable outcomes received by the unprivileged group to the privileged group.\",\n",
      "  \"ideal\": \"The ideal value of this metric is 0.0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(format_json(json_expl_q5.mean_difference()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5:** Are your observations in line with what you expected in Q4 above? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5_Write your answer in this text cell:**\n",
    "\n",
    "|      | Original Data | Model's Predictions over test data   | Reweighing Data   | Model's Predictions over RW data   |\n",
    "| :---        |    :----:   |          ---: |         ---: |        ---: |\n",
    "| **Mean difference**  | -0.115     | -0.1252   |  -1.110   | -0.0799   |\n",
    "| **Disparate Impact** | 0.8477     | 0.7738    |  0.9999    | 0.8597    |\n",
    "\n",
    "While the disparate impact shows what I expected, the mean difference does not. Instead, the mean difference value shows the most ideal among the others. In addition, even if the model's prediction over reweighing data is lower than the fairness of the original reweighing data, when I compare each model's predictions over each data, the prediction over reweighing data shows better fairness than the other in both values.\n",
    "\n",
    "The observation does not align with what I expected from the data and the model because we manipulated the data and used another model, so these differences are enough to show different values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6:** Instead of reweighing, one could also apply techniques such as suppression, i.e. removing sensitive attributes. Write code below to train a model that does not use any information on the sensitive attribute, use this model to make predictions over the test data, and then compute the fairness metrics over the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4e6cf01f3fc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgerman_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGermanDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Remove sensitive attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgerman_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\aif360\\datasets\\german_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         super(GermanDataset, self).__init__(df=df, label_name=label_name,\n\u001b[0m\u001b[0;32m     92\u001b[0m             \u001b[0mfavorable_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfavorable_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0mprotected_attribute_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotected_attribute_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\aif360\\datasets\\standard_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, df, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, scores_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                 \u001b[1;31m# find all instances which match any of the attribute values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                 \u001b[0mpriv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpriv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprivileged_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mpriv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munprivileged_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2015\u001b[0m     ):\n\u001b[1;32m-> 2016\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marraylike\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_ufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2018\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[1;31m# e.g. np.negative (only one reached), with \"where\" and \"out\" in kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36mreconstruct\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"outer\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "german_data = GermanDataset(features_to_keep)\n",
    "\n",
    "# Remove sensitive attributes\n",
    "german_data.drop(['age', 'sex'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_german\n",
    "\n",
    "preproc_gd   = load_preproc_data_german()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               instance weights            features                            \\\n",
      "                                protected attribute                             \n",
      "                                                age  sex credit_history=Delay   \n",
      "instance names                                                                  \n",
      "0                           1.0                 1.0  1.0                  0.0   \n",
      "1                           1.0                 0.0  0.0                  0.0   \n",
      "2                           1.0                 1.0  1.0                  0.0   \n",
      "3                           1.0                 1.0  1.0                  0.0   \n",
      "4                           1.0                 1.0  1.0                  1.0   \n",
      "...                         ...                 ...  ...                  ...   \n",
      "995                         1.0                 1.0  0.0                  0.0   \n",
      "996                         1.0                 1.0  1.0                  0.0   \n",
      "997                         1.0                 1.0  1.0                  0.0   \n",
      "998                         1.0                 0.0  1.0                  0.0   \n",
      "999                         1.0                 1.0  1.0                  0.0   \n",
      "\n",
      "                                                                           \\\n",
      "                                                                            \n",
      "               credit_history=None/Paid credit_history=Other savings=500+   \n",
      "instance names                                                              \n",
      "0                                   0.0                  1.0          0.0   \n",
      "1                                   1.0                  0.0          0.0   \n",
      "2                                   0.0                  1.0          0.0   \n",
      "3                                   1.0                  0.0          0.0   \n",
      "4                                   0.0                  0.0          0.0   \n",
      "...                                 ...                  ...          ...   \n",
      "995                                 1.0                  0.0          0.0   \n",
      "996                                 1.0                  0.0          0.0   \n",
      "997                                 1.0                  0.0          0.0   \n",
      "998                                 1.0                  0.0          0.0   \n",
      "999                                 0.0                  1.0          0.0   \n",
      "\n",
      "                                                                       \\\n",
      "                                                                        \n",
      "               savings=<500 savings=Unknown/None employment=1-4 years   \n",
      "instance names                                                          \n",
      "0                       0.0                  1.0                  0.0   \n",
      "1                       1.0                  0.0                  1.0   \n",
      "2                       1.0                  0.0                  0.0   \n",
      "3                       1.0                  0.0                  0.0   \n",
      "4                       1.0                  0.0                  1.0   \n",
      "...                     ...                  ...                  ...   \n",
      "995                     1.0                  0.0                  0.0   \n",
      "996                     1.0                  0.0                  1.0   \n",
      "997                     1.0                  0.0                  0.0   \n",
      "998                     1.0                  0.0                  1.0   \n",
      "999                     1.0                  0.0                  0.0   \n",
      "\n",
      "                                                         labels  \n",
      "                                                                 \n",
      "               employment=4+ years employment=Unemployed         \n",
      "instance names                                                   \n",
      "0                              1.0                   0.0    1.0  \n",
      "1                              0.0                   0.0    2.0  \n",
      "2                              1.0                   0.0    1.0  \n",
      "3                              1.0                   0.0    1.0  \n",
      "4                              0.0                   0.0    2.0  \n",
      "...                            ...                   ...    ...  \n",
      "995                            1.0                   0.0    1.0  \n",
      "996                            0.0                   0.0    1.0  \n",
      "997                            1.0                   0.0    1.0  \n",
      "998                            0.0                   0.0    2.0  \n",
      "999                            0.0                   1.0    1.0  \n",
      "\n",
      "[1000 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(preproc_gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_logit_model_suppression(dset_trn,\n",
    "                                  dset_tst,\n",
    "                                  privileged_groups,\n",
    "                                  unprivileged_groups):\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_trn  = scaler.fit_transform(dset_trn.features[:, 2:]) \n",
    "    y_trn  = dset_trn.labels.ravel()\n",
    "    w_trn  = dset_trn.instance_weights.ravel()\n",
    "\n",
    "    lmod = LogisticRegression()\n",
    "    lmod.fit(X_trn, y_trn,\n",
    "             sample_weight = w_trn) \n",
    "\n",
    "    dset_tst_pred = dset_tst.copy(deepcopy=True)\n",
    "    X_tst = scaler.transform(dset_tst_pred.features[:, 2:]) \n",
    "    dset_tst_pred.labels = lmod.predict(X_tst)\n",
    "\n",
    "    metric_tst = BinaryLabelDatasetMetric(dset_tst_pred, \n",
    "                                          unprivileged_groups,\n",
    "                                          privileged_groups)\n",
    "    print(\"Disparate impact is %0.2f (closer to 1 is better)\" %\n",
    "           metric_tst.disparate_impact())\n",
    "    print(\"Mean difference  is %0.2f (closer to 0 is better)\" %\n",
    "           metric_tst.mean_difference())\n",
    "\n",
    "    return lmod, dset_tst_pred, metric_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1ced15d5ae49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlabel_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Good Credit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Bad Credit'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprotected_attribute_maps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Male'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Female'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m gd = GermanDataset(protected_attribute_names=['sex'],\n\u001b[0m\u001b[0;32m      4\u001b[0m privileged_classes=[['male']], metadata={'label_map': label_map,\n\u001b[0;32m      5\u001b[0m 'protected_attribute_maps': protected_attribute_maps})\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\aif360\\datasets\\german_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         super(GermanDataset, self).__init__(df=df, label_name=label_name,\n\u001b[0m\u001b[0;32m     92\u001b[0m             \u001b[0mfavorable_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfavorable_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0mprotected_attribute_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotected_attribute_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\aif360\\datasets\\standard_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, df, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, scores_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                 \u001b[1;31m# find all instances which match any of the attribute values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                 \u001b[0mpriv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpriv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprivileged_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mpriv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munprivileged_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2015\u001b[0m     ):\n\u001b[1;32m-> 2016\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marraylike\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_ufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2018\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[1;31m# e.g. np.negative (only one reached), with \"where\" and \"out\" in kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36mreconstruct\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"outer\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# write code here to implement suppression\n",
    "dataset_orig_sup = GermanDataset()\n",
    "\n",
    "\n",
    "dataset_orig_train_sup, dataset_orig_test_sup = dataset_orig_sup.split([0.7], shuffle=True)\n",
    "\n",
    "# metric_orig_train_sup = BinaryLabelDatasetMetric(\n",
    "#      dataset_orig_train_sup, \n",
    "#      unprivileged_groups=unprivileged_groups,\n",
    "#      privileged_groups=privileged_groups\n",
    "#   )\n",
    "# print(\"Original training dataset_suppressing\")\n",
    "# print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train_sup.mean_difference())\n",
    "# print(\"Original training dataset_suppressing\")\n",
    "# print(\"Disparate Impact = %f\" % metric_orig_train_sup.disparate_impact())\n",
    "# # json_expl_sup = MetricJSONExplainer(metric_orig_train_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               instance weights features                \\\n",
      "                                                         \n",
      "                                   month credit_amount   \n",
      "instance names                                           \n",
      "0                           1.0      6.0        1169.0   \n",
      "1                           1.0     48.0        5951.0   \n",
      "2                           1.0     12.0        2096.0   \n",
      "3                           1.0     42.0        7882.0   \n",
      "4                           1.0     24.0        4870.0   \n",
      "...                         ...      ...           ...   \n",
      "995                         1.0     12.0        1736.0   \n",
      "996                         1.0     30.0        3857.0   \n",
      "997                         1.0     12.0         804.0   \n",
      "998                         1.0     45.0        1845.0   \n",
      "999                         1.0     45.0        4576.0   \n",
      "\n",
      "                                                                \\\n",
      "                                                                 \n",
      "               investment_as_income_percentage residence_since   \n",
      "instance names                                                   \n",
      "0                                          4.0             4.0   \n",
      "1                                          2.0             2.0   \n",
      "2                                          2.0             3.0   \n",
      "3                                          2.0             4.0   \n",
      "4                                          3.0             4.0   \n",
      "...                                        ...             ...   \n",
      "995                                        3.0             4.0   \n",
      "996                                        4.0             4.0   \n",
      "997                                        4.0             4.0   \n",
      "998                                        4.0             4.0   \n",
      "999                                        3.0             4.0   \n",
      "\n",
      "                                                                        \\\n",
      "               protected attribute                                       \n",
      "                               age number_of_credits people_liable_for   \n",
      "instance names                                                           \n",
      "0                              1.0               2.0               1.0   \n",
      "1                              0.0               1.0               1.0   \n",
      "2                              1.0               1.0               2.0   \n",
      "3                              1.0               1.0               2.0   \n",
      "4                              1.0               2.0               2.0   \n",
      "...                            ...               ...               ...   \n",
      "995                            1.0               1.0               1.0   \n",
      "996                            1.0               1.0               1.0   \n",
      "997                            1.0               1.0               1.0   \n",
      "998                            0.0               1.0               1.0   \n",
      "999                            1.0               1.0               1.0   \n",
      "\n",
      "                                      ...                                \\\n",
      "                                      ...                                 \n",
      "               status=A11 status=A12  ... housing=A153 skill_level=A171   \n",
      "instance names                        ...                                 \n",
      "0                     1.0        0.0  ...          0.0              0.0   \n",
      "1                     0.0        1.0  ...          0.0              0.0   \n",
      "2                     0.0        0.0  ...          0.0              0.0   \n",
      "3                     1.0        0.0  ...          1.0              0.0   \n",
      "4                     1.0        0.0  ...          1.0              0.0   \n",
      "...                   ...        ...  ...          ...              ...   \n",
      "995                   0.0        0.0  ...          0.0              0.0   \n",
      "996                   1.0        0.0  ...          0.0              0.0   \n",
      "997                   0.0        0.0  ...          0.0              0.0   \n",
      "998                   1.0        0.0  ...          1.0              0.0   \n",
      "999                   0.0        1.0  ...          0.0              0.0   \n",
      "\n",
      "                                                                   \\\n",
      "                                                                    \n",
      "               skill_level=A172 skill_level=A173 skill_level=A174   \n",
      "instance names                                                      \n",
      "0                           0.0              1.0              0.0   \n",
      "1                           0.0              1.0              0.0   \n",
      "2                           1.0              0.0              0.0   \n",
      "3                           0.0              1.0              0.0   \n",
      "4                           0.0              1.0              0.0   \n",
      "...                         ...              ...              ...   \n",
      "995                         1.0              0.0              0.0   \n",
      "996                         0.0              0.0              1.0   \n",
      "997                         0.0              1.0              0.0   \n",
      "998                         0.0              1.0              0.0   \n",
      "999                         0.0              1.0              0.0   \n",
      "\n",
      "                                                                  \\\n",
      "                                                                   \n",
      "               telephone=A191 telephone=A192 foreign_worker=A201   \n",
      "instance names                                                     \n",
      "0                         0.0            1.0                 1.0   \n",
      "1                         1.0            0.0                 1.0   \n",
      "2                         1.0            0.0                 1.0   \n",
      "3                         1.0            0.0                 1.0   \n",
      "4                         1.0            0.0                 1.0   \n",
      "...                       ...            ...                 ...   \n",
      "995                       1.0            0.0                 1.0   \n",
      "996                       0.0            1.0                 1.0   \n",
      "997                       1.0            0.0                 1.0   \n",
      "998                       0.0            1.0                 1.0   \n",
      "999                       1.0            0.0                 1.0   \n",
      "\n",
      "                                   labels  \n",
      "                                           \n",
      "               foreign_worker=A202         \n",
      "instance names                             \n",
      "0                              0.0    1.0  \n",
      "1                              0.0    2.0  \n",
      "2                              0.0    1.0  \n",
      "3                              0.0    1.0  \n",
      "4                              0.0    2.0  \n",
      "...                            ...    ...  \n",
      "995                            0.0    1.0  \n",
      "996                            0.0    1.0  \n",
      "997                            0.0    1.0  \n",
      "998                            0.0    2.0  \n",
      "999                            0.0    1.0  \n",
      "\n",
      "[1000 rows x 59 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that we drop sex, which may also be a protected attribute\n",
    "dataset_orig = GermanDataset(protected_attribute_names=['age'],\n",
    "                             privileged_classes=[lambda x: x >= 25],\n",
    "                             features_to_drop=['personal_status', 'sex'])\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "\n",
    "default_mappings = {\n",
    "    'label_maps': [{1.0: 'Good Credit', 2.0: 'Bad Credit'}],\n",
    "    'protected_attribute_maps': [{1.0: 'Male', 0.0: 'Female'},\n",
    "                                 {1.0: 'Old', 0.0: 'Young'}],\n",
    "}\n",
    "\n",
    "def default_preprocessing(df):\n",
    "    \"\"\"Adds a derived sex attribute based on personal_status.\"\"\"\n",
    "    # TODO: ignores the value of privileged_classes for 'sex'\n",
    "    status_map = {'A91': 'male', 'A93': 'male', 'A94': 'male',\n",
    "                  'A92': 'female', 'A95': 'female'}\n",
    "    df['sex'] = df['personal_status'].replace(status_map)\n",
    "\n",
    "    return df\n",
    "\n",
    "class GermanDataset(StandardDataset):\n",
    "    \"\"\"German credit Dataset.\n",
    "\n",
    "    See :file:`aif360/data/raw/german/README.md`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, label_name='credit', favorable_classes=[1],\n",
    "                 protected_attribute_names=['sex', 'age'],\n",
    "                 privileged_classes=[['male'], lambda x: x > 25],\n",
    "                 instance_weights_name=None,\n",
    "                 categorical_features=['status', 'credit_history', 'purpose',\n",
    "                     'savings', 'employment', 'other_debtors', 'property',\n",
    "                     'installment_plans', 'housing', 'skill_level', 'telephone',\n",
    "                     'foreign_worker'],\n",
    "                 features_to_keep=[], features_to_drop=['personal_status'],\n",
    "                 na_values=[], custom_preprocessing=default_preprocessing,\n",
    "                 metadata=default_mappings):\n",
    "        \"\"\"See :obj:`StandardDataset` for a description of the arguments.\n",
    "\n",
    "        By default, this code converts the 'age' attribute to a binary value\n",
    "        where privileged is `age > 25` and unprivileged is `age <= 25` as\n",
    "        proposed by Kamiran and Calders [1]_.\n",
    "\n",
    "        References:\n",
    "            .. [1] F. Kamiran and T. Calders, \"Classifying without\n",
    "               discriminating,\" 2nd International Conference on Computer,\n",
    "               Control and Communication, 2009.\n",
    "\n",
    "        Examples:\n",
    "            In some cases, it may be useful to keep track of a mapping from\n",
    "            `float -> str` for protected attributes and/or labels. If our use\n",
    "            case differs from the default, we can modify the mapping stored in\n",
    "            `metadata`:\n",
    "\n",
    "            >>> label_map = {1.0: 'Good Credit', 0.0: 'Bad Credit'}\n",
    "            >>> protected_attribute_maps = [{1.0: 'Male', 0.0: 'Female'}]\n",
    "            >>> gd = GermanDataset(protected_attribute_names=['sex'],\n",
    "            ... privileged_classes=[['male']], metadata={'label_map': label_map,\n",
    "            ... 'protected_attribute_maps': protected_attribute_maps})\n",
    "\n",
    "            Now this information will stay attached to the dataset and can be\n",
    "            used for more descriptive visualizations.\n",
    "        \"\"\"\n",
    "\n",
    "        filepath = os.path.join(os.path.dirname(os.path.abspath(__file__)),\n",
    "                                '..', 'data', 'raw', 'german', 'german.data')\n",
    "        # as given by german.doc\n",
    "        column_names = ['status', 'month', 'credit_history',\n",
    "            'purpose', 'credit_amount', 'savings', 'employment',\n",
    "            'investment_as_income_percentage', 'personal_status',\n",
    "            'other_debtors', 'residence_since', 'property', 'age',\n",
    "            'installment_plans', 'housing', 'number_of_credits',\n",
    "            'skill_level', 'people_liable_for', 'telephone',\n",
    "            'foreign_worker', 'credit']\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, sep=' ', header=None, names=column_names,\n",
    "                             na_values=na_values)\n",
    "        except IOError as err:\n",
    "            print(\"IOError: {}\".format(err))\n",
    "            print(\"To use this class, please download the following files:\")\n",
    "            print(\"\\n\\thttps://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\")\n",
    "            print(\"\\thttps://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\")\n",
    "            print(\"\\nand place them, as-is, in the folder:\")\n",
    "            print(\"\\n\\t{}\\n\".format(os.path.abspath(os.path.join(\n",
    "                os.path.abspath(__file__), '..', '..', 'data', 'raw', 'german'))))\n",
    "            import sys\n",
    "            sys.exit(1)\n",
    "\n",
    "        super(GermanDataset, self).__init__(df=df, label_name=label_name,\n",
    "            favorable_classes=favorable_classes,\n",
    "            protected_attribute_names=protected_attribute_names,\n",
    "            privileged_classes=privileged_classes,\n",
    "            instance_weights_name=instance_weights_name,\n",
    "            categorical_features=categorical_features,\n",
    "            features_to_keep=features_to_keep,\n",
    "            features_to_drop=features_to_drop, na_values=na_values,\n",
    "            custom_preprocessing=custom_preprocessing, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_mappings = {\n",
    "    'label_maps': [{1.0: 'Good Credit', 2.0: 'Bad Credit'}],\n",
    "    'protected_attribute_maps': [{1.0: 'Male', 0.0: 'Female'},\n",
    "                                 {1.0: 'Old', 0.0: 'Young'}],\n",
    "}\n",
    "\n",
    "def default_preprocessing(df):\n",
    "    \"\"\"Adds a derived sex attribute based on personal_status.\"\"\"\n",
    "    # TODO: ignores the value of privileged_classes for 'sex'\n",
    "    status_map = {'A91': 'male', 'A93': 'male', 'A94': 'male',\n",
    "                  'A92': 'female', 'A95': 'female'}\n",
    "    df['sex'] = df['personal_status'].replace(status_map)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-42ab5cfd4c09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m dataset_orig_sss = GermanDataset(protected_attribute_names=[],\n\u001b[0m\u001b[0;32m      2\u001b[0m                              \u001b[0mprivileged_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'male'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                              features_to_drop=[])\n",
      "\u001b[1;32m<ipython-input-25-4a27ccbb9f85>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \"\"\"\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         filepath = os.path.join(os.path.dirname(os.path.abspath(__file__)),\n\u001b[0m\u001b[0;32m     68\u001b[0m                                 '..', 'data', 'raw', 'german', 'german.data')\n\u001b[0;32m     69\u001b[0m         \u001b[1;31m# as given by german.doc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_orig_sss = GermanDataset(protected_attribute_names=[],\n",
    "                             privileged_classes=[['male'], lambda x: x >= 25],\n",
    "                             features_to_drop=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GermanDataset' object has no attribute 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-cf9d313e938d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset_orig_sss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GermanDataset' object has no attribute 'drop'"
     ]
    }
   ],
   "source": [
    "dataset_orig_sss.drop(['sex', 'age'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "convert_to_dataframe() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-76ab23c88444>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_sup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_df_sup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_orig_sup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_sup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# print(df.columns)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# df.head(5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: convert_to_dataframe() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "df_sup, dict_df_sup = dataset_orig_sup.convert_to_dataframe()\n",
    "print(\"Shape: \", df_sup.shape)\n",
    "# print(df.columns)\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "\n",
    "df_test, dict_df_test = dataset_orig_test.convert_to_dataframe()\n",
    "df_train, dict_df_train = dataset_orig_train.convert_to_dataframe()\n",
    "\n",
    "# Fit the model to the training data\n",
    "x_train = df_train.drop(['credit'], axis=1)\n",
    "y_train = df_train['credit']\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "x_test = df_test.drop(['credit'], axis=1)\n",
    "y_test = df_test['credit']\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "dataset_pred_test = dataset_orig_test.copy()\n",
    "dataset_pred_test.labels = y_pred.copy()\n",
    "\n",
    "metric_dataset_test = BinaryLabelDatasetMetric(\n",
    "    dataset_pred_test, \n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7:** Interpret your results. How does the preprocessing technique in Q5 compare to the suppression technique? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer in this text cell:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riLalr-WwDsG"
   },
   "source": [
    "### 4.2. Bias Mitigation via In-Processing\n",
    "\n",
    "In-processing methods focus on the model training stage, as compared to pre-processing which focuses on transforming the data prior to model training. Broadly speaking, contemporary in-processing methods are stronger than pre-processing methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUZKKFAo1R1v"
   },
   "source": [
    "### Adversarial Debiasing\n",
    "\n",
    "In this part of the notebook, we will use an in-processing algorithm, called _Adversarial Debiasing_, that we briefly discussed in class. From the aif360 documentation (https://aif360.readthedocs.io/en/v0.2.3/modules/inprocessing.html):\n",
    "\n",
    "> Adversarial debiasing is an in-processing technique that learns a classifier to maximize prediction accuracy and simultaneously reduce an adversary’s ability to determine the protected attribute from the predictions. This approach leads to a fair classifier as the predictions cannot carry any group discrimination information that the adversary can exploit.\n",
    "\n",
    "For intuition, you can think of adversarial debiasing as a model with two supervised learning tasks. The first task is to predict an outcome using the training data input. The second task, i.e. the adversary, is to predict a protected feature using these predictions and non-protected features in the training data input. The aim is to maximize the model's ability to carry out the first task (i.e. predict outcomes) while minimizing its ability to carry out the second task (i.e. predict protected features).\n",
    "\n",
    "We implement adversarial debiasing below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4551,
     "status": "ok",
     "timestamp": 1643739523668,
     "user": {
      "displayName": "Aniruddha Chauhan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16209082779696786371"
     },
     "user_tz": 300
    },
    "id": "M_rWLmHvwBFF",
    "outputId": "79b78b63-dff7-4c8a-a9a4-3ca9448f8d89",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-7370112a1483>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mscope_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'debiased_classifier'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdebias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     sess = sess)\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# fit the model to training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "# reset tensorflow graph\n",
    "# tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# start tensorflow session\n",
    "# sess = tf.compat.v1.Session()\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# create AdversarialDebiasing model\n",
    "debiased_model = AdversarialDebiasing(\n",
    "    privileged_groups = privileged_groups,\n",
    "    unprivileged_groups = unprivileged_groups,\n",
    "    scope_name = 'debiased_classifier',\n",
    "    debias = True,\n",
    "    sess = sess)\n",
    "\n",
    "# fit the model to training data\n",
    "debiased_model.fit(dataset_orig_train)\n",
    "\n",
    "# make predictions on training and test data\n",
    "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)\n",
    "\n",
    "# metrics\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(\n",
    "    dataset_debiasing_test, \n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups\n",
    "  )\n",
    "\n",
    "# Close session\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'reset_default_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-a14577a40dc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# reset tensorflow graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# start tensorflow session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'reset_default_graph'"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as tf\n",
    "\n",
    "# reset tensorflow graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# start tensorflow session\n",
    "sess = tf.Session()\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "# create AdversarialDebiasing model\n",
    "debiased_model = AdversarialDebiasing(\n",
    "    privileged_groups = privileged_groups,\n",
    "    unprivileged_groups = unprivileged_groups,\n",
    "    scope_name = 'debiased_classifier',\n",
    "    debias = True,\n",
    "    sess = sess)\n",
    "\n",
    "# fit the model to training data\n",
    "debiased_model.fit(dataset_orig_train)\n",
    "\n",
    "# make predictions on training and test data\n",
    "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)\n",
    "\n",
    "# metrics\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(\n",
    "    dataset_debiasing_test, \n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups\n",
    "  )\n",
    "\n",
    "# Close session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWJUD_1-1XOe"
   },
   "source": [
    "### Fairness Metrics under Adversarial Debiasing\n",
    "\n",
    "The adversarial debiasing algorithm has built-in methods for the difference in mean outcomes (called ```.mean_difference()```) and disparate impact (called ```.disparate_impact()```). Print these below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1643739523668,
     "user": {
      "displayName": "Aniruddha Chauhan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16209082779696786371"
     },
     "user_tz": 300
    },
    "id": "ro-8nuS62NZx",
    "outputId": "d0cab299-c5af-472b-cbae-5c7e77cc1707"
   },
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIQcc23c7SNA"
   },
   "source": [
    "**Q8:** Interpret the difference in means and disparate impact for the predicted outcomes under adversarial debiasing. How do these compare to the metrics calculated in Q2 and Q5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3MyIpCk7hnp"
   },
   "source": [
    "**Write your interpretation and comparison in this text cell:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Bias Mitigation via Post-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this last section, we will use one of the post-processing algorithms in AI Fairness 360 called as **equalized odds postprocessing**, which is implemented in the `EqOddsPostprocessing` class in the `aif360.algorithms.postprocessing` package. This technique solves a linear program to find probabilities with which to change output labels to optimize equalized odds.\n",
    "\n",
    "You can find documentation for reweighting here:\n",
    "https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.postprocessing.EqOddsPostprocessing.html \n",
    "\n",
    "Call the fit and transform methods to perform the transformation, producing a newly transformed training dataset (```dataset_post_train```):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test, dict_df_test = dataset_orig_test.convert_to_dataframe()\n",
    "df_train, dict_df_train = dataset_orig_train.convert_to_dataframe()\n",
    "\n",
    "# Fit the model to the training data and predict for test data\n",
    "# write code here\n",
    "# dataset_pred_test -- dataset with predictions stored in labels\n",
    "\n",
    "# create Equalized Odds Post processing object\n",
    "eo_post = EqOddsPostprocessing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "\n",
    "# fit the object to training data\n",
    "eo_post.fit(dataset_orig_test, dataset_pred_test)\n",
    "\n",
    "# make predictions on test data\n",
    "# write code here\n",
    "\n",
    "# construct metrics object\n",
    "# write code here\n",
    "\n",
    "# compute fairnesss metrics \n",
    "# write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9:** Interpret the difference in fairness metrics for the predicted outcomes under this post-processing technique. How do these compare to the metrics calculated in Q2, Q5 and Q8?\n",
    "\n",
    "**Write your interpretation and comparison in this text cell:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting this Assignment Notebook\n",
    "\n",
    "Once complete, please submit your assignment notebook as an attachment under \\\"Assignments > Assignment 4\\\" on Brightspace. You can download a copy of your notebook using ```File > Download .ipynb```. Please ensure you submit the `.ipynb` file (and not a `.py` file).\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab_2",
   "provenance": [
    {
     "file_id": "1hSONDCewgk6NlUWjqiT6Qf4I0GoUKTrW",
     "timestamp": 1612381728169
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
